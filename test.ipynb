{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# from typing import List\n",
    "# from numpy.typing import list\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "# import audiotools\n",
    "\n",
    "from pathlib import PurePath\n",
    "import pickle\n",
    "# from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flac to wav test\n",
    "# origindir=DATASET_AUDIO_PATH\n",
    "# convertdir=root_path+\"train_wav\"\n",
    "# originpath=DATASET_AUDIO_PATH+\"/spk001/spk001_002.flac\"\n",
    "# convertpath=root_path+\"train_wav/\"+originpath.split('/')[-2]+\"/\"+originpath.split('/')[-1].split('.')[0]+\".wav\"\n",
    "\n",
    "# print(originpath)\n",
    "# print(\"/\".join(convertpath.split('/')[0:-1]))\n",
    "# if os.path.exists(\"/\".join(convertpath.split('/')[0:-1])) is False:\n",
    "#     os.makedirs(\"/\".join(convertpath.split('/')[0:-1]))\n",
    "# os.system('ffmpeg -i %s %s' % (originpath,convertpath))\n",
    "\n",
    "# test load flac file\n",
    "# torchaudio.load(DATASET_AUDIO_PATH+\"spk001/spk001_002.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "VALID_SPLIT = 0.1\n",
    "SHUFFLE_SEED = 43\n",
    "SAMPLING_RATE = 16000\n",
    "SCALE = 0.5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "\n",
    "LENGTH = 8*16000\n",
    "\n",
    "AUDIO_IDX=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spk013', 'spk222', 'spk077', 'spk007', 'spk153', 'spk020', 'spk058', 'spk113', 'spk026', 'spk140', 'spk155', 'spk080', 'spk195', 'spk122', 'spk249', 'spk150', 'spk090', 'spk211', 'spk176', 'spk124', 'spk215', 'spk169', 'spk171', 'spk049', 'spk225', 'spk181', 'spk210', 'spk219', 'spk108', 'spk166', 'spk243', 'spk156', 'spk148', 'spk134', 'spk099', 'spk151', 'spk182', 'spk208', 'spk034', 'spk220', 'spk223', 'spk207', 'spk174', 'spk098', 'spk184', 'spk089', 'spk006', 'spk136', 'spk097', 'spk027', 'spk094', 'spk111', 'spk073', 'spk014', 'spk192', 'spk056', 'spk237', 'spk228', 'spk248', 'spk091', 'spk074', 'spk046', 'spk149', 'spk082', 'spk186', 'spk138', 'spk202', 'spk247', 'spk160', 'spk180', 'spk064', 'spk204', 'spk114', 'spk175', 'spk235', 'spk055', 'spk062', 'spk019', 'spk028', 'spk102', 'spk107', 'spk036', 'spk163', 'spk146', 'spk023', 'spk011', 'spk053', 'spk022', 'spk112', 'spk041', 'spk227', 'spk003', 'spk065', 'spk130', 'spk199', 'spk095', 'spk185', 'spk240', 'spk177', 'spk002', 'spk232', 'spk004', 'spk164', 'spk115', 'spk076', 'spk078', 'spk212', 'spk030', 'spk119', 'spk173', 'spk214', 'spk190', 'spk103', 'spk044', 'spk205', 'spk137', 'spk043', 'spk012', 'spk194', 'spk125', 'spk161', 'spk157', 'spk145', 'spk213', 'spk135', 'spk015', 'spk127', 'spk141', 'spk234', 'spk154', 'spk246', 'spk170', 'spk197', 'spk050', 'spk242', 'spk244', 'spk162', 'spk198', 'spk183', 'spk236', 'spk068', 'spk189', 'spk087', 'spk084', 'spk209', 'spk224', 'spk196', 'spk226', 'spk132', 'spk031', 'spk042', 'spk159', 'spk239', 'spk133', 'spk233', 'spk216', 'spk231', 'spk045', 'spk024', 'spk038', 'spk059', 'spk126', 'spk165', 'spk035', 'spk096', 'spk245', 'spk179', 'spk109', 'spk010', 'spk009', 'spk018', 'spk120', 'spk241', 'spk238', 'spk193', 'spk001', 'spk144', 'spk086', 'spk201', 'spk118', 'spk101', 'spk106', 'spk081', 'spk005', 'spk221', 'spk123', 'spk139', 'spk152', 'spk021', 'spk093', 'spk029', 'spk079', 'spk054', 'spk039', 'spk191', 'spk206', 'spk172', 'spk037', 'spk116', 'spk100', 'spk017', 'spk131', 'spk187', 'spk052', 'spk105', 'spk129', 'spk121', 'spk016', 'spk217', 'spk061', 'spk203', 'spk067', 'spk071', 'spk057', 'spk069', 'spk110', 'spk200', 'spk063', 'spk051', 'spk229', 'spk075', 'spk250', 'spk188', 'spk032', 'spk230', 'spk008', 'spk070', 'spk085', 'spk083', 'spk066', 'spk092', 'spk033', 'spk143', 'spk142', 'spk147', 'spk040', 'spk025', 'spk047', 'spk218', 'spk168', 'spk117', 'spk128', 'spk158', 'spk072', 'spk178', 'spk088', 'spk167', 'spk060', 'spk048', 'spk104']\n"
     ]
    }
   ],
   "source": [
    "# # generate dataset\n",
    "# root_path=\"/home/lizz_lab/cse12232433/project/aai_project/data/LibriSpeech-SI/\";\n",
    "# train=\"train_wav\";\n",
    "# noise=\"noise_wav\";\n",
    "# test=\"test_wav\";\n",
    "# test_noise=\"test_noise_wav\";\n",
    "\n",
    "# DATASET_AUDIO_PATH = os.path.join(root_path,train)\n",
    "# DATASET_NOISE_PATH = os.path.join(root_path,noise)\n",
    "\n",
    "# # get all audio data path and label\n",
    "# # get class_names firts, then add audio data to data_X, class_names to label_Y\n",
    "# class_names = os.listdir(DATASET_AUDIO_PATH)\n",
    "# X=[];Y=[];\n",
    "# def listdir_addXY(path, labels, X, Y):\n",
    "#     for label in labels:\n",
    "#         for file in os.listdir(path+'/'+label):\n",
    "#             file_path = os.path.join(path+'/'+label, file)\n",
    "#             if os.path.isdir(file_path):\n",
    "#                 listdir_addXY(file_path, X, Y)\n",
    "#             else:\n",
    "#                 X.append(file_path)\n",
    "#                 Y.append(label)\n",
    "# listdir_addXY(DATASET_AUDIO_PATH,class_names,X,Y)\n",
    "# Y = torch.as_tensor(preprocessing.LabelEncoder().fit_transform(Y))\n",
    "# print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 12,  12,  12,  ..., 103, 103, 103])\n"
     ]
    }
   ],
   "source": [
    "# # load processed X,Y\n",
    "# with open(\"X.pkl\",mode=\"wb\") as f:\n",
    "#     pickle.dump(X, f)\n",
    "# with open(\"Y.pkl\",mode=\"wb\") as f:\n",
    "#     pickle.dump(Y, f)\n",
    "\n",
    "if os.path.exists('X.pkl'):\n",
    "    X=pickle.load(open('X.pkl','rb'))\n",
    "\n",
    "if os.path.exists('Y.pkl'):\n",
    "    Y=pickle.load(open('Y.pkl','rb'))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_length(audio):\n",
    "    if audio.size()[0] >= LENGTH:\n",
    "        return audio[0:LENGTH]\n",
    "    else:\n",
    "        audio = torch.cat((audio,audio),0)\n",
    "        return fixed_length(audio) \n",
    "\n",
    "# def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "#     \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
    "\n",
    "def path_to_audio(path):\n",
    "    \"\"\"Reads and decodes an audio file. data size should have same length\"\"\"\n",
    "    audio,sample_rate=torchaudio.load(path)\n",
    "    if sample_rate != SAMPLING_RATE:\n",
    "        print(\"error samplerate\")\n",
    "    else:\n",
    "        audio = audio.squeeze()\n",
    "        return fixed_length(audio)\n",
    "# audio=fixed_length(path_to_audio(X[0]))\n",
    "\n",
    "# def add_noise(audio, noises=None, scale=0.5):\n",
    "#     \"\"\"add noise to data\"\"\"\n",
    "\n",
    "def audio_to_fft(audio):\n",
    "    \"\"\"do fft\"\"\"\n",
    "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
    "    # we need to squeeze the dimensions and then expand them again\n",
    "    # after FFT\n",
    "    # print(audio.size())\n",
    "    fft = torch.fft.fft(audio)[0:len(audio)//2]\n",
    "    # plt.plot(fft)\n",
    "    global AUDIO_IDX\n",
    "    AUDIO_IDX=AUDIO_IDX+1\n",
    "    return torch.abs(fft)\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, audio_paths, labels):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        audio_path = self.audio_paths[idx]\n",
    "        audio = path_to_audio(audio_path)\n",
    "        fft = audio_to_fft(audio)\n",
    "        fft=fft.unsqueeze(dim=-2)\n",
    "        label = torch.tensor(self.labels[idx]) \n",
    "        return fft,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "ResNet(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (maxpool1): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(32, 128, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=2048, out_features=250, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "# use residential block\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# residential block  todo group, conv use groups\n",
    "class Bottleneck(nn.Module):\n",
    "    # output channels = expansion * input channels\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, conv_nums=3, down_sample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel*self.expansion, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channel*self.expansion)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# whole model for acoustic signal feature\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block=Bottleneck, blocks_num=[3, 4, 6, 3, 3], num_classes=250, include_top=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 32\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1,self.in_channel, kernel_size=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_channel)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=3,stride=2,padding=1) # stride=2 padding=1 size/2\n",
    "        self.layer1 = self._make_layer(block, 32, block_num=blocks_num[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 64, block_num=blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, block_num=blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, block_num=blocks_num[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 512, block_num=blocks_num[4], stride=2)\n",
    "\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "            self.fc = nn.Linear(in_features=512*block.expansion,out_features=num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d): # normal distribution initialize the weights\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, channel, block_num=3, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, padding=0)\n",
    "                # nn.BatchNorm1d(channel * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channel,\n",
    "                channel,\n",
    "                downsample=downsample,\n",
    "                stride=stride,\n",
    "            )\n",
    "        )\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.in_channel,\n",
    "                    channel\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # print(batch)\n",
    "        # try:\n",
    "        #     X, y = X.to(device), y.to(device)\n",
    "        # except:\n",
    "        #     print(batch,X,y)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\",flush=True)\n",
    "\n",
    "\n",
    "# test\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # try:\n",
    "            #     X, y = X.to(device), y.to(device)\n",
    "            # except:\n",
    "            #     print(X,y)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# parameters init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "data_set = dataset(X,Y)\n",
    "data_sizes=len(data_set)\n",
    "train_len=int(data_sizes*0.8)\n",
    "test_len=data_sizes-train_len\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(data_set,[train_len,test_len],generator=torch.Generator().manual_seed(42))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# for X, y in test_dataloader:\n",
    "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174800/4225093754.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.994688 [    0/18537]\n",
      "loss: 5.502486 [ 1600/18537]\n",
      "loss: 5.133015 [ 3200/18537]\n",
      "loss: 4.661965 [ 4800/18537]\n",
      "loss: 4.652112 [ 6400/18537]\n",
      "loss: 4.531713 [ 8000/18537]\n",
      "loss: 4.441274 [ 9600/18537]\n",
      "loss: 4.464667 [11200/18537]\n",
      "loss: 4.272813 [12800/18537]\n",
      "loss: 4.106117 [14400/18537]\n",
      "loss: 3.759906 [16000/18537]\n",
      "loss: 4.021405 [17600/18537]\n",
      "Test Error: \n",
      " Accuracy: 15.2%, Avg loss: 4.048604 \n",
      "\n",
      "loss: 3.713618 [    0/18537]\n",
      "loss: 3.931945 [ 1600/18537]\n",
      "loss: 4.006107 [ 3200/18537]\n",
      "loss: 3.036970 [ 4800/18537]\n",
      "loss: 3.287104 [ 6400/18537]\n",
      "loss: 3.111061 [ 8000/18537]\n",
      "loss: 3.057064 [ 9600/18537]\n",
      "loss: 3.870358 [11200/18537]\n",
      "loss: 3.281099 [12800/18537]\n",
      "loss: 3.128790 [14400/18537]\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.__version__,torchaudio.__version__)\n",
    "\n",
    "# torch.cuda.device_count()\n",
    "# torch.cuda.get_device_name(0)\n",
    "\n",
    "# m = nn.Conv1d(1, 16, 3, stride=1, padding=1)\n",
    "# pool = nn.MaxPool1d(3,2,1)\n",
    "# avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "# input = torch.randn(1, 16, 50)\n",
    "# output = avgpool(input)\n",
    "# output = torch.flatten(output, 1)\n",
    "# output.size()\n",
    "\n",
    "# a=torch.randn(64000)\n",
    "# y=torch.randn(3)\n",
    "# a_pred=model(a.to(device))\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=[\"path\"]\n",
    "# for i in path:\n",
    "#     print(i)\n",
    "\n",
    "# audio.shape[0]\n",
    "# # audio = audio[1:10*16000]\n",
    "# # a= audio.squeeze()\n",
    "\n",
    "# fft = audio_to_fft(audio)\n",
    "\n",
    "# train_data = dataset(X,Y)\n",
    "# data = train_set.__getitem__(1)\n",
    "\n",
    "# plt.plot(data[0])\n",
    "# audio=path_to_audio(X[2])\n",
    "# fft = audio_to_fft(audio)\n",
    "# fft=fft.unsqueeze(dim=-2)\n",
    "\n",
    "# audio,sample_rate=torchaudio.load(X[2])\n",
    "# audio = audio.squeeze()\n",
    "# # audio=fixed_length(audio)\n",
    "# audio = torch.cat((audio,audio),0)\n",
    "# audio = audio[0:LENGTH]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c96ea6eee3f189d6a3522a7be340530b5a03fd7a132cf9cb0615165f22252ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
