{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# from typing import List\n",
    "# from numpy.typing import list\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "# import audiotools\n",
    "\n",
    "from pathlib import PurePath\n",
    "import pickle\n",
    "# from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flac to wav test\n",
    "# origindir=DATASET_AUDIO_PATH\n",
    "# convertdir=root_path+\"train_wav\"\n",
    "# originpath=DATASET_AUDIO_PATH+\"/spk001/spk001_002.flac\"\n",
    "# convertpath=root_path+\"train_wav/\"+originpath.split('/')[-2]+\"/\"+originpath.split('/')[-1].split('.')[0]+\".wav\"\n",
    "\n",
    "# print(originpath)\n",
    "# print(\"/\".join(convertpath.split('/')[0:-1]))\n",
    "# if os.path.exists(\"/\".join(convertpath.split('/')[0:-1])) is False:\n",
    "#     os.makedirs(\"/\".join(convertpath.split('/')[0:-1]))\n",
    "# os.system('ffmpeg -i %s %s' % (originpath,convertpath))\n",
    "\n",
    "# test load flac file\n",
    "# torchaudio.load(DATASET_AUDIO_PATH+\"spk001/spk001_002.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "VALID_SPLIT = 0.1\n",
    "SHUFFLE_SEED = 43\n",
    "SAMPLING_RATE = 16000\n",
    "SCALE = 0.5\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "\n",
    "LENGTH = 8*16000\n",
    "\n",
    "AUDIO_IDX=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "# root_path=\"/mnt/f/workspace/AAI_project/LibriSpeech-SI/\";\n",
    "# train=\"train_wav\";\n",
    "# noise=\"noise_wav\";\n",
    "# test=\"test_wav\";\n",
    "# test_noise=\"test_noise_wav\";\n",
    "\n",
    "# DATASET_AUDIO_PATH = os.path.join(root_path,train)\n",
    "# DATASET_NOISE_PATH = os.path.join(root_path,noise)\n",
    "\n",
    "# # get all audio data path and label\n",
    "# # get class_names firts, then add audio data to data_X, class_names to label_Y\n",
    "# class_names = os.listdir(DATASET_AUDIO_PATH)\n",
    "# X=[];Y=[];\n",
    "# def listdir_addXY(path, labels, X, Y):\n",
    "#     for label in labels:\n",
    "#         for file in os.listdir(path+'/'+label):\n",
    "#             file_path = os.path.join(path+'/'+label, file)\n",
    "#             if os.path.isdir(file_path):\n",
    "#                 listdir_addXY(file_path, X, Y)\n",
    "#             else:\n",
    "#                 X.append(file_path)\n",
    "#                 Y.append(label)\n",
    "# listdir_addXY(DATASET_AUDIO_PATH,class_names,X,Y)\n",
    "# Y = torch.as_tensor(preprocessing.LabelEncoder().fit_transform(Y))\n",
    "# print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed X,Y\n",
    "# with open(\"X.pkl\",mode=\"wb\") as f:\n",
    "#     pickle.dump(X, f)\n",
    "# with open(\"Y.pkl\",mode=\"wb\") as f:\n",
    "#     pickle.dump(Y, f)\n",
    "\n",
    "if os.path.exists('X.pkl'):\n",
    "    X=pickle.load(open('X.pkl','rb'))\n",
    "\n",
    "if os.path.exists('Y.pkl'):\n",
    "    Y=pickle.load(open('Y.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_length(audio):\n",
    "    if audio.size()[0] >= LENGTH:\n",
    "        return audio[0:LENGTH]\n",
    "    else:\n",
    "        audio = torch.cat((audio,audio),0)\n",
    "        return fixed_length(audio) \n",
    "\n",
    "# def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "#     \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
    "\n",
    "def path_to_audio(path):\n",
    "    \"\"\"Reads and decodes an audio file. data size should have same length\"\"\"\n",
    "    audio,sample_rate=torchaudio.load(path)\n",
    "    if sample_rate != SAMPLING_RATE:\n",
    "        print(\"error samplerate\")\n",
    "    else:\n",
    "        audio = audio.squeeze()\n",
    "        return fixed_length(audio)\n",
    "# audio=fixed_length(path_to_audio(X[0]))\n",
    "\n",
    "# def add_noise(audio, noises=None, scale=0.5):\n",
    "#     \"\"\"add noise to data\"\"\"\n",
    "\n",
    "def audio_to_fft(audio):\n",
    "    \"\"\"do fft\"\"\"\n",
    "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
    "    # we need to squeeze the dimensions and then expand them again\n",
    "    # after FFT\n",
    "    # print(audio.size())\n",
    "    fft = torch.fft.fft(audio)[0:len(audio)//2]\n",
    "    # plt.plot(fft)\n",
    "    global AUDIO_IDX\n",
    "    AUDIO_IDX=AUDIO_IDX+1\n",
    "    return torch.abs(fft)\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, audio_paths, labels):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        audio_path = self.audio_paths[idx]\n",
    "        audio = path_to_audio(audio_path)\n",
    "        fft = audio_to_fft(audio)\n",
    "        fft=fft.unsqueeze(dim=-2)\n",
    "        label = torch.tensor(self.labels[idx]) \n",
    "        return fft,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "ResNet(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(1,), stride=(1,))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (maxpool1): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(32, 128, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=2048, out_features=250, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "# use residential block\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# residential block  todo group, conv use groups\n",
    "class Bottleneck(nn.Module):\n",
    "    # output channels = expansion * input channels\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, conv_nums=3, down_sample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel*self.expansion, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# whole model for acoustic signal feature\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block=Bottleneck, blocks_num=[3, 4, 6, 3, 3], num_classes=250, include_top=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 32\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1,self.in_channel, kernel_size=1,padding=0)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=3,stride=2,padding=1) # stride=2 padding=1 size/2\n",
    "        self.layer1 = self._make_layer(block, 32, block_num=blocks_num[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 64, block_num=blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, block_num=blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, block_num=blocks_num[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 512, block_num=blocks_num[4], stride=2)\n",
    "\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "            self.fc = nn.Linear(in_features=512*block.expansion,out_features=num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d): # normal distribution initialize the weights\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, channel, block_num=3, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, padding=0)\n",
    "                # nn.BatchNorm1d(channel * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channel,\n",
    "                channel,\n",
    "                downsample=downsample,\n",
    "                stride=stride,\n",
    "            )\n",
    "        )\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.in_channel,\n",
    "                    channel\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # print(batch)\n",
    "        # try:\n",
    "        #     X, y = X.to(device), y.to(device)\n",
    "        # except:\n",
    "        #     print(batch,X,y)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\",flush=True)\n",
    "\n",
    "\n",
    "# test\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # try:\n",
    "            #     X, y = X.to(device), y.to(device)\n",
    "            # except:\n",
    "            #     print(X,y)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([4, 1, 64000])\n",
      "Shape of y: torch.Size([4]) torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2529524/4225093754.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx])\n"
     ]
    }
   ],
   "source": [
    "# loss function and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "data_set = dataset(X,Y)\n",
    "data_sizes=len(data_set)\n",
    "train_len=int(data_sizes*0.8)\n",
    "test_len=data_sizes-train_len\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(data_set,[train_len,test_len],generator=torch.Generator().manual_seed(42))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# for X, y in test_dataloader:\n",
    "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2529524/4225093754.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 0.8%, Avg loss: 5.340520 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.is_available())\n",
    "\n",
    "# print(torch.__version__,torchaudio.__version__)\n",
    "\n",
    "# torch.cuda.device_count()\n",
    "# torch.cuda.get_device_name(0)\n",
    "\n",
    "# m = nn.Conv1d(1, 16, 3, stride=1, padding=1)\n",
    "# pool = nn.MaxPool1d(3,2,1)\n",
    "# avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "# input = torch.randn(1, 16, 50)\n",
    "# output = avgpool(input)\n",
    "# output = torch.flatten(output, 1)\n",
    "# output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=[\"path\"]\n",
    "# for i in path:\n",
    "#     print(i)\n",
    "\n",
    "# audio.shape[0]\n",
    "# # audio = audio[1:10*16000]\n",
    "# # a= audio.squeeze()\n",
    "\n",
    "# fft = audio_to_fft(audio)\n",
    "\n",
    "# train_data = dataset(X,Y)\n",
    "# data = train_set.__getitem__(1)\n",
    "\n",
    "# plt.plot(data[0])\n",
    "# audio=path_to_audio(X[2])\n",
    "# fft = audio_to_fft(audio)\n",
    "# fft=fft.unsqueeze(dim=-2)\n",
    "\n",
    "# audio,sample_rate=torchaudio.load(X[2])\n",
    "# audio = audio.squeeze()\n",
    "# # audio=fixed_length(audio)\n",
    "# audio = torch.cat((audio,audio),0)\n",
    "# audio = audio[0:LENGTH]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af9a4742c87393642c9d87741961abc476412f9fe8d66839a9b0b6bb15da9051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
